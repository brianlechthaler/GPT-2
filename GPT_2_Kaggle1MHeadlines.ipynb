{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GPT-2_Kaggle1MHeadlines.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ccea20a17c5b47cb9093f275116d3b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9d8b006350534a9288a61499060122c9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bf25a20b38494b0494e1b1fb7a3f97fb",
              "IPY_MODEL_bbdf915d8bdb4a15ac7a6b31757bbe72"
            ]
          }
        },
        "9d8b006350534a9288a61499060122c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "bf25a20b38494b0494e1b1fb7a3f97fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6b017ea076164f47a3b5f7902325ec6b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1186017,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1186017,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6eced6dd59347788de2aa7924db14db"
          }
        },
        "bbdf915d8bdb4a15ac7a6b31757bbe72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9375e7ab6d1f4b6094cac54b0a54a4f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1186017/1186017 [00:39&lt;00:00, 29761.57it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f0146c8410544e73b09fa7819a8d1366"
          }
        },
        "6b017ea076164f47a3b5f7902325ec6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6eced6dd59347788de2aa7924db14db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9375e7ab6d1f4b6094cac54b0a54a4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f0146c8410544e73b09fa7819a8d1366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a735dda5a0b4df086b284f10e8a9796": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d46de2bf9f594ec1a9f6f192c4ba3570",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dc871c655b9c4bbabfe6f3dca4052ca2",
              "IPY_MODEL_36f18c6803094d429725fb0fdd40659b"
            ]
          }
        },
        "d46de2bf9f594ec1a9f6f192c4ba3570": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "dc871c655b9c4bbabfe6f3dca4052ca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4b24a7c34c544c168b75d4d029719f3f",
            "_dom_classes": [],
            "description": "Loss: 3.929 â€” Avg: 3.936 â€” GPU Mem: 2471 MB: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 25000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 25000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eeff2aa540f44237a0c76f508c071f27"
          }
        },
        "36f18c6803094d429725fb0fdd40659b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_94d3d1c7f1c8489f99da08ff7acccf77",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 25000/25000 [53:10&lt;00:00,  7.84it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e56835ffc2194f15a65ef3f2aa762da8"
          }
        },
        "4b24a7c34c544c168b75d4d029719f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eeff2aa540f44237a0c76f508c071f27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94d3d1c7f1c8489f99da08ff7acccf77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e56835ffc2194f15a65ef3f2aa762da8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJX_nTQogJp6"
      },
      "source": [
        "# GPT-2 News Headline Generation\n",
        "\n",
        "## tl;dr\n",
        "1. `Connect` or `Reconnect`\n",
        "2. Upload your Kaggle API key (instructions included later)\n",
        "3. `Runtime` -> `Restart and run all`\n",
        "4. Wait 15-30 minutes\n",
        "5. Laugh at weird computer-generated headlines\n",
        "\n",
        "\n",
        "by Brian Lechthaler, \n",
        "*based on [aitextgen](https://github.com/minimaxir/aitextgen)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dMTiyLIgnAc",
        "outputId": "1383ff45-587d-4ebb-bb3c-f2afcf4aef5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from datetime import datetime\n",
        "def mktimestamp():\n",
        "  timestamp = datetime.now()\n",
        "  msg = \"Last Updated: \" + str(timestamp)\n",
        "  return msg\n",
        "print(mktimestamp())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Last Updated: 2020-11-12 07:49:38.854455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8tXdKjUhard"
      },
      "source": [
        "# Dependencies\n",
        "Download and install all necessary dependencies with `pip`, then `import` what we need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIJGHezJewYk",
        "outputId": "843e6678-b30f-45d8-e96e-da7675047c7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Freeze versions of dependencies for now\n",
        "!pip install -q transformers==2.9.1\n",
        "!pip install -q pytorch-lightning==0.7.6\n",
        "\n",
        "!pip install -q aitextgen\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "        format=\"%(asctime)s â€” %(levelname)s â€” %(name)s â€” %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO\n",
        "    )\n",
        "\n",
        "from aitextgen import aitextgen\n",
        "from aitextgen.colab import mount_gdrive, copy_file_from_gdrive\n",
        "from aitextgen.TokenDataset import TokenDataset, merge_datasets\n",
        "from aitextgen.utils import build_gpt2_config\n",
        "from aitextgen.tokenizers import train_tokenizer"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 645kB 5.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 30.0MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 45.4MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8MB 49.7MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256kB 2.9MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 829kB 7.1MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 573kB 6.0MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 9.5MB/s \n",
            "\u001b[?25h  Building wheel for aitextgen (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11/12/2020 07:50:02 â€” INFO â€” transformers.file_utils â€” PyTorch version 1.7.0+cu101 available.\n",
            "11/12/2020 07:50:03 â€” INFO â€” transformers.file_utils â€” TensorFlow version 2.3.0 available.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w9n5ZkShpY9"
      },
      "source": [
        "# Mount Google Drive\n",
        "Because any data in the VM this notebook is running on will be nuked once the Jupyter kernel stops running, it's helpful to mount your Google Drive to the Colab VM to persist some files that we'll use in this notebook.\n",
        "\n",
        "*Note:* your data will not be shared with anyone who does not have direct access to the VM running this Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfDol0OZfAPq"
      },
      "source": [
        "#mount_gdrive()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r7Q-truvtgv"
      },
      "source": [
        "# Download Dataset from Kaggle\n",
        "Downloads the 'million-headlines' dataset contributed by Kaggle user `therohk`\n",
        "\n",
        "1.   Sign into Kaggle in a separate tab\n",
        "2.   Click [this link](https://kaggle.com/me/account) to go to your Kaggle account settings\n",
        "3. Under the `API` section, click/tap `Create new API token`. If this is not the first time you have followed this step, consider clicking `Expire API Token` prior to generating a new token.\n",
        "4. In the Colab file browser, upload the `kaggle.json` API token you just downloaded in step 3.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2x4M0GMrHTQ"
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEv2I3USrkiY",
        "outputId": "8acf4432-b3f0-494b-d913-386d1c5ed0cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!mkdir -p /root/.kaggle\n",
        "!mv kaggle.json /root/.kaggle/kaggle.json\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!rm -rf million-headlines.zip\n",
        "!kaggle datasets download -d therohk/million-headlines"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading million-headlines.zip to /content\n",
            " 79% 16.0M/20.2M [00:00<00:00, 32.5MB/s]\n",
            "100% 20.2M/20.2M [00:00<00:00, 58.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47PdWd5qPdwU",
        "outputId": "2edcb1a8-4f1c-46e1-8107-5ecb4e5c17b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!rm -rf abcnews-date-text.csv\n",
        "!unzip million-headlines.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  million-headlines.zip\n",
            "  inflating: abcnews-date-text.csv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpTYzc74yW20"
      },
      "source": [
        "# Transform Dataset\n",
        "We need to define a couple functions to "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSiUS4G4Pn--"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QVCB4OHaAiw"
      },
      "source": [
        "def writeln(line, path):\n",
        "  line = line + \"\\n\"\n",
        "  with open(path, 'a') as saveto:\n",
        "    saveto.write(line)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UteGdkjXafm"
      },
      "source": [
        "def finalsave(df, colname, filename):\n",
        "  print(\"Transforming dataset...\")\n",
        "  for index, row in df.iterrows():\n",
        "    line = row[colname]\n",
        "    writeln(line, filename)\n",
        "  print(\"Done!\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9YNAjHUxkqR"
      },
      "source": [
        "# Create a Ramdisk for our Dataset\n",
        "This is a little-known trick for Linux systems to create a temporary file store in memory and mount it at `/media/ramdisk`. This speeds up the transform we need to make on our dataset in a little bit, as well as speeds up copying our dataset into GPU memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogQ5mPefqYcT"
      },
      "source": [
        "!sudo mkdir -p /media/ramdisk\n",
        "!sudo mount -t tmpfs -o size=128M tmpfs /media/ramdisk"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuxO5d2APtSe"
      },
      "source": [
        "dataset_csv = '/content/abcnews-date-text.csv'\n",
        "csvingest = pd.read_csv(dataset_csv)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXXTbC2iLOM6"
      },
      "source": [
        "*Important Note:* If the next cell crashes your Colab runtime, you probably ran out of memory. Sorry, but if the problem persists you may need to shell out $10 to Google for Colab Pro and change the runtime to GPU High RAM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpDVwLJ_d7eL",
        "outputId": "90cf590a-aeb7-418e-98fe-4b14ba12ace3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!rm -rf /content/dataset.csv\n",
        "!touch /content/dataset.csv\n",
        "file_name = '/media/ramdisk/dataset.csv'\n",
        "finalsave(csvingest, 'headline_text', file_name)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Transforming dataset...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCP7Yr_VibKI"
      },
      "source": [
        "# Train the Tokenizer\n",
        "This runs on the CPU and may take a few minutes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWVrLbVCohZ7",
        "outputId": "88cf532a-a963-496e-e611-96656c5eb470",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_tokenizer(file_name)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11/12/2020 07:54:09 â€” INFO â€” aitextgen.tokenizers â€” Saving aitextgen-vocab.json and aitextgen-merges.txt to the current directory. You will need both files to build the GPT2Tokenizer.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tixuti80omSE"
      },
      "source": [
        "# Configure GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSZ4m8yTopQr",
        "outputId": "0690f29d-26d2-4707-d197-14ff70d33818",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "config = build_gpt2_config(vocab_size=5000, max_length=16, dropout=0.0, n_embd=256, n_layer=8, n_head=8)\n",
        "config"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2Config {\n",
              "  \"activation_function\": \"gelu_new\",\n",
              "  \"attn_pdrop\": 0.0,\n",
              "  \"bos_token_id\": 0,\n",
              "  \"embd_pdrop\": 0.0,\n",
              "  \"eos_token_id\": 0,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"layer_norm_epsilon\": 1e-05,\n",
              "  \"model_type\": \"gpt2\",\n",
              "  \"n_ctx\": 16,\n",
              "  \"n_embd\": 256,\n",
              "  \"n_head\": 8,\n",
              "  \"n_layer\": 8,\n",
              "  \"n_positions\": 16,\n",
              "  \"resid_pdrop\": 0.0,\n",
              "  \"summary_activation\": null,\n",
              "  \"summary_first_dropout\": 0.0,\n",
              "  \"summary_proj_to_labels\": true,\n",
              "  \"summary_type\": \"cls_index\",\n",
              "  \"summary_use_proj\": true,\n",
              "  \"vocab_size\": 5000\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIbsF9Owos1b",
        "outputId": "87818b7c-82f7-435f-8489-516bcc2356ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ai = aitextgen(config=config,\n",
        "               vocab_file=\"aitextgen-vocab.json\",\n",
        "               merges_file=\"aitextgen-merges.txt\",\n",
        "               to_gpu=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11/12/2020 07:54:10 â€” INFO â€” aitextgen â€” Constructing GPT-2 model from provided config.\n",
            "11/12/2020 07:54:10 â€” INFO â€” aitextgen â€” Using a custom tokenizer.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXVGip1HoxNM"
      },
      "source": [
        "# Finetune GPT-2 to dataset\n",
        "Training should take about an hour on an NVidia Tesla P100 GPU. Text generated from the model should get progressively better over iterations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aamon3x-owP3",
        "outputId": "941e52ba-cdd6-4920-d1ee-e8073f953114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ccea20a17c5b47cb9093f275116d3b65",
            "9d8b006350534a9288a61499060122c9",
            "bf25a20b38494b0494e1b1fb7a3f97fb",
            "bbdf915d8bdb4a15ac7a6b31757bbe72",
            "6b017ea076164f47a3b5f7902325ec6b",
            "e6eced6dd59347788de2aa7924db14db",
            "9375e7ab6d1f4b6094cac54b0a54a4f6",
            "f0146c8410544e73b09fa7819a8d1366",
            "6a735dda5a0b4df086b284f10e8a9796",
            "d46de2bf9f594ec1a9f6f192c4ba3570",
            "dc871c655b9c4bbabfe6f3dca4052ca2",
            "36f18c6803094d429725fb0fdd40659b",
            "4b24a7c34c544c168b75d4d029719f3f",
            "eeff2aa540f44237a0c76f508c071f27",
            "94d3d1c7f1c8489f99da08ff7acccf77",
            "e56835ffc2194f15a65ef3f2aa762da8"
          ]
        }
      },
      "source": [
        "ai.train(file_name,\n",
        "         line_by_line=True,\n",
        "         num_steps=25000,\n",
        "         generate_every=1000,\n",
        "         save_every=1000,\n",
        "         save_gdrive=False,\n",
        "         learning_rate=1e-4,\n",
        "         batch_size=256,\n",
        "         )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccea20a17c5b47cb9093f275116d3b65",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1186017.0), HTML(value='')), layout=Layouâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "11/12/2020 07:54:25 â€” INFO â€” aitextgen.TokenDataset â€” Encoding 1,186,017 rows from /media/ramdisk/dataset.csv.\n",
            "GPU available: True, used: True\n",
            "11/12/2020 07:55:05 â€” INFO â€” lightning â€” GPU available: True, used: True\n",
            "No environment variable for node rank defined. Set as 0.\n",
            "11/12/2020 07:55:05 â€” WARNING â€” lightning â€” No environment variable for node rank defined. Set as 0.\n",
            "CUDA_VISIBLE_DEVICES: [0]\n",
            "11/12/2020 07:55:05 â€” INFO â€” lightning â€” CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a735dda5a0b4df086b284f10e8a9796",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=25000.0), HTML(value='')), layout=Layout(â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\u001b[1m1,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m1,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "last of the pampy\n",
            "==========\n",
            "\u001b[1m2,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m2,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "labor warns dunlot\n",
            "==========\n",
            "\u001b[1m3,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m3,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "cairns police seek to be unite\n",
            "==========\n",
            "\u001b[1m4,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m4,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "twire to be stops in the australian\n",
            "==========\n",
            "\u001b[1m5,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m5,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "police investigate hit and run\n",
            "==========\n",
            "\u001b[1m6,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m6,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "rspca to face trial after fatal kemp fire\n",
            "==========\n",
            "\u001b[1m7,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m7,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "wednesday weather\n",
            "==========\n",
            "\u001b[1m8,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m8,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "dry season begins\n",
            "==========\n",
            "\u001b[1m9,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m9,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "qld government to protect them\n",
            "==========\n",
            "\u001b[1m10,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m10,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "the drum monday january 11\n",
            "==========\n",
            "\u001b[1m11,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m11,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "man faces court over assault of 7yo girl\n",
            "==========\n",
            "\u001b[1m12,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m12,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "michelle guy to be anyone man\n",
            "==========\n",
            "\u001b[1m13,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m13,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "goulburn valley drought outlook\n",
            "==========\n",
            "\u001b[1m14,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m14,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "tuesday markets with marcus padley\n",
            "==========\n",
            "\u001b[1m15,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m15,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "james ryan talks about his future\n",
            "==========\n",
            "\u001b[1m16,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m16,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "newman seeks to stop mining tax stance\n",
            "==========\n",
            "\u001b[1m17,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m17,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "wimbledon stakes in the spotlight\n",
            "==========\n",
            "\u001b[1m18,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m18,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "sydney to hobart roar\n",
            "==========\n",
            "\u001b[1m19,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m19,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "eight die in philippinesi kremlin in us\n",
            "==========\n",
            "\u001b[1m20,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m20,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "the drum thursday may 15\n",
            "==========\n",
            "\u001b[1m21,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m21,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "wilkie urges government to maintain\n",
            "==========\n",
            "\u001b[1m22,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m22,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "hail hits northern nsw\n",
            "==========\n",
            "\u001b[1m23,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m23,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "tiwi islands tourism workers strike over\n",
            "==========\n",
            "\u001b[1m24,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m24,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "santos to buy local farms\n",
            "==========\n",
            "\u001b[1m25,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m25,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "lobby group welcomes funding for mdb review\n",
            "==========\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11/12/2020 08:47:57 â€” INFO â€” aitextgen â€” Saving trained model pytorch_model.bin to /trained_model\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0kW0lpZo85M"
      },
      "source": [
        "# Generate a few Samples\n",
        "Now, for the fun part! Before I continue, I want to be really clear: all headlines you see in this notebook are 100% fake and generated by GPT-2.  Please use this code responsibly (that means never use this to intentionally decieve people, generate clickbait, or do anything else blackhatty)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9YEwLVHpAYO",
        "outputId": "0396c2a1-3040-4b4c-f94c-b595a9168e7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ai.generate(n=15,\n",
        "            batch_size=1024,\n",
        "            temperature=1.0,\n",
        "            top_p=0.999)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "police probe school stabbings\n",
            "==========\n",
            "rann announces new indigenous plan\n",
            "==========\n",
            "sternone to sue for umpiring\n",
            "==========\n",
            "jericho our economy and is what happening this summer\n",
            "==========\n",
            "former detective sinks nietrack\n",
            "==========\n",
            "heart tips for lnp paedophiles in\n",
            "==========\n",
            "pearson wins golden gifts cup\n",
            "==========\n",
            "man charged over fathers stabbing\n",
            "==========\n",
            "extra money for drought declarations in sa\n",
            "==========\n",
            "simplot management\n",
            "==========\n",
            "rural tas nsw oadamante\n",
            "==========\n",
            "choppy season for loncy\n",
            "==========\n",
            "cabelle beck to remain as tamarine\n",
            "==========\n",
            "newman calls for more indigenous intervention\n",
            "==========\n",
            "toronto battery barkly lanter\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMs-joQL0PRs"
      },
      "source": [
        "# Credits\n",
        "\n",
        "This project was made possible by the cumulative efforts of the following parties:\n",
        "\n",
        "Brian Lechthaler *author of this notebook*\n",
        "* https://github.com/brianlechthaler\n",
        "* https://twitter.com/brianlechthaler\n",
        "\n",
        "Max Woolf *author of [aitextgen](https://github.com/minimaxir/aitextgen), the training code this notebook is based on.*\n",
        "* https://minimaxir.com/\n",
        "* https://github.com/minimaxir\n",
        "\n",
        "Rohit Kulkarni *author of [million-headlines](https://www.kaggle.com/therohk/million-headlines) dataset*\n",
        "* https://www.linkedin.com/in/rohit-kulkarni-21b0724a/\n",
        "* https://kaggle.com/therohk\n",
        "\n",
        "OpenAI *creators of [GPT-2](https://en.wikipedia.org/wiki/OpenAI#GPT-2) model*\n",
        "* https://openai.com \n",
        "* https://openai.com/blog/tags/gpt-2/\n"
      ]
    }
  ]
}