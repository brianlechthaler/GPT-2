{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT_2_Anime",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dfdd17f53c3f40f8a70d32533cdde614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3c48f068a5e943a09b23ea1a3c481264",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_502f53367de540a8b4eb08aaa5788cdd",
              "IPY_MODEL_30dd45018a344da4a6bf33e89ef69c98"
            ]
          }
        },
        "3c48f068a5e943a09b23ea1a3c481264": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "502f53367de540a8b4eb08aaa5788cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d87017499b524b31bca29385567cc721",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1248751,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1248751,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_88cfeb2b38c54fb0980c2883389a7d10"
          }
        },
        "30dd45018a344da4a6bf33e89ef69c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_43e2c7d4e31b4d3d98bb469d378d2f62",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1248751/1248751 [00:37&lt;00:00, 33304.38it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7e57933d659843d586e38c865fbd2553"
          }
        },
        "d87017499b524b31bca29385567cc721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "88cfeb2b38c54fb0980c2883389a7d10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43e2c7d4e31b4d3d98bb469d378d2f62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7e57933d659843d586e38c865fbd2553": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ef4ba6a6c6541edb802774673a88a76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_53bc38e4b81045c1a511a755e5109121",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_510bc69df90f40b8b671a9a6179a6d57",
              "IPY_MODEL_bc60c67b5bb84abbb6698507c5228c3c"
            ]
          }
        },
        "53bc38e4b81045c1a511a755e5109121": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "510bc69df90f40b8b671a9a6179a6d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_09a996f5c0504c15845698261495879c",
            "_dom_classes": [],
            "description": "Loss: 2.403 — Avg: 2.407 — GPU Mem: 13797 MB: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 25000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 25000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_57d999dd976146968c08cb2676211445"
          }
        },
        "bc60c67b5bb84abbb6698507c5228c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b3d722c61d434dc1a69361381db42590",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 25000/25000 [1:47:00&lt;00:00,  3.89it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b632751ff60a418fb5da781b3340426d"
          }
        },
        "09a996f5c0504c15845698261495879c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "57d999dd976146968c08cb2676211445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3d722c61d434dc1a69361381db42590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b632751ff60a418fb5da781b3340426d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yrd5h0gCHkz"
      },
      "source": [
        "# GPT-2 Anime Subtitle Generation\n",
        "\n",
        "## tl;dr\n",
        "1. `Connect` or `Reconnect`\n",
        "2. Upload your Kaggle API key (instructions included later)\n",
        "3. `Runtime` -> `Restart and run all`\n",
        "4. Wait 15-30 minutes\n",
        "5. Laugh at weird computer-generated Kickstarter projects\n",
        "\n",
        "\n",
        "by Brian Lechthaler, \n",
        "*based on [aitextgen](https://github.com/minimaxir/aitextgen)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOHCCCA6CWwB"
      },
      "source": [
        "# Dependencies\n",
        "Download and install all necessary dependencies with `pip`, then `import` what we need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sulzsy5WHC0",
        "outputId": "f5011de3-d939-4cf5-fdad-f466e429d50e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -q kaggle\n",
        "# Freeze versions of dependencies for now\n",
        "!pip install -q transformers==2.9.1\n",
        "!pip install -q pytorch-lightning==0.7.6\n",
        "\n",
        "!pip install -q aitextgen\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "        format=\"%(asctime)s — %(levelname)s — %(name)s — %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO\n",
        "    )\n",
        "\n",
        "from aitextgen import aitextgen\n",
        "from aitextgen.colab import mount_gdrive, copy_file_from_gdrive\n",
        "from aitextgen.TokenDataset import TokenDataset, merge_datasets\n",
        "from aitextgen.utils import build_gpt2_config\n",
        "from aitextgen.tokenizers import train_tokenizer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11/14/2020 07:18:27 — INFO — transformers.file_utils — PyTorch version 1.7.0+cu101 available.\n",
            "11/14/2020 07:18:28 — INFO — transformers.file_utils — TensorFlow version 2.3.0 available.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eII1AiBFCbEV"
      },
      "source": [
        "# Mount Google Drive\n",
        "Because any data in the VM this notebook is running on will be nuked once the Jupyter kernel stops running, it's helpful to mount your Google Drive to the Colab VM to persist some files that we'll use in this notebook.\n",
        "\n",
        "*Note:* your data will not be shared with anyone who does not have direct access to the VM running this Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYznWbR_WSl3"
      },
      "source": [
        "#mount_gdrive()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBoUdBX-CfiG"
      },
      "source": [
        "# Download Dataset from Kaggle\n",
        "Downloads the 'kickstarter-projects' dataset contributed by Kaggle user `jef1056`\n",
        "\n",
        "1.   Sign into Kaggle in a separate tab\n",
        "2.   Click [this link](https://kaggle.com/me/account) to go to your Kaggle account settings\n",
        "3. Under the `API` section, click/tap `Create new API token`. If this is not the first time you have followed this step, consider clicking `Expire API Token` prior to generating a new token.\n",
        "4. In the Colab file browser, upload the `kaggle.json` API token you just downloaded in step 3.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_TLQ9yZPPga",
        "outputId": "e2e38bd9-0fa0-4f2f-ac5b-e2f280cea572",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!mkdir -p /root/.kaggle\n",
        "!mv kaggle.json /root/.kaggle/kaggle.json\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "#!rm -rf anime-subtitles.zip\n",
        "#!kaggle datasets download -d jef1056/anime-subtitles\n",
        "#!rm -rf 'Anime Datasets V3.zip'\n",
        "#!rm -rf 'input (Cleaned).txt'\n",
        "#!unzip anime-subtitles.zip\n",
        "#!wc -l 'input (Cleaned).txt'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'kaggle.json': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_cF-EYGCmrd"
      },
      "source": [
        "# Train Tokenizer on Dataset\n",
        "Bound to CPU, may take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1KxWMyNXQsZ"
      },
      "source": [
        "file_name = 'input (Cleaned).txt'\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfCKKkOsayuX"
      },
      "source": [
        "!rm -rf aitextgen-merges.txt\n",
        "!rm -rf aitextgen-vocab.json"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwgXjOmxXcLm",
        "outputId": "bb54d505-2837-4f8e-9c7f-0d6b53da6b0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_tokenizer(file_name)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11/14/2020 07:19:03 — INFO — aitextgen.tokenizers — Saving aitextgen-vocab.json and aitextgen-merges.txt to the current directory. You will need both files to build the GPT2Tokenizer.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thbsjNCtCx3S"
      },
      "source": [
        "# Configure GPT-2 Training\n",
        "Set various configuration variables to control how the GPT-2 model is re-trained to the data we are feeding it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI-RgLNzX2eZ",
        "outputId": "eac5c8ab-6740-4789-cccc-264737edd787",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "config = build_gpt2_config(vocab_size=30000, \n",
        "                           max_length=64, \n",
        "                           dropout=0.0, \n",
        "                           n_embd=256, \n",
        "                           n_layer=8, \n",
        "                           n_head=8)\n",
        "config"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2Config {\n",
              "  \"activation_function\": \"gelu_new\",\n",
              "  \"attn_pdrop\": 0.0,\n",
              "  \"bos_token_id\": 0,\n",
              "  \"embd_pdrop\": 0.0,\n",
              "  \"eos_token_id\": 0,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"layer_norm_epsilon\": 1e-05,\n",
              "  \"model_type\": \"gpt2\",\n",
              "  \"n_ctx\": 64,\n",
              "  \"n_embd\": 256,\n",
              "  \"n_head\": 8,\n",
              "  \"n_layer\": 8,\n",
              "  \"n_positions\": 64,\n",
              "  \"resid_pdrop\": 0.0,\n",
              "  \"summary_activation\": null,\n",
              "  \"summary_first_dropout\": 0.0,\n",
              "  \"summary_proj_to_labels\": true,\n",
              "  \"summary_type\": \"cls_index\",\n",
              "  \"summary_use_proj\": true,\n",
              "  \"vocab_size\": 30000\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c91npByBX5is",
        "outputId": "ca1b5af5-05e0-4470-cf35-0be099cc1060",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ai = aitextgen(config=config,\n",
        "               vocab_file=\"aitextgen-vocab.json\",\n",
        "               merges_file=\"aitextgen-merges.txt\",\n",
        "               to_gpu=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11/14/2020 07:19:03 — INFO — aitextgen — Constructing GPT-2 model from provided config.\n",
            "11/14/2020 07:19:04 — INFO — aitextgen — Using a custom tokenizer.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3nFDdkiDBnt"
      },
      "source": [
        "# Re-train GPT-2 to Dataset\n",
        "\n",
        "This task is bound to the GPU and should take just under two hours to train on an NVidia V100 GPU.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTf7z7GEasfo"
      },
      "source": [
        "!rm -rf trained_model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWIbNQuHYBK5",
        "outputId": "33007116-87b3-4f6f-cf23-15dc7d2799b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "dfdd17f53c3f40f8a70d32533cdde614",
            "3c48f068a5e943a09b23ea1a3c481264",
            "502f53367de540a8b4eb08aaa5788cdd",
            "30dd45018a344da4a6bf33e89ef69c98",
            "d87017499b524b31bca29385567cc721",
            "88cfeb2b38c54fb0980c2883389a7d10",
            "43e2c7d4e31b4d3d98bb469d378d2f62",
            "7e57933d659843d586e38c865fbd2553",
            "5ef4ba6a6c6541edb802774673a88a76",
            "53bc38e4b81045c1a511a755e5109121",
            "510bc69df90f40b8b671a9a6179a6d57",
            "bc60c67b5bb84abbb6698507c5228c3c",
            "09a996f5c0504c15845698261495879c",
            "57d999dd976146968c08cb2676211445",
            "b3d722c61d434dc1a69361381db42590",
            "b632751ff60a418fb5da781b3340426d"
          ]
        }
      },
      "source": [
        "ai.train(file_name,\n",
        "         line_by_line=True,\n",
        "         num_steps=25000,\n",
        "         generate_every=1000,\n",
        "         save_every=500,\n",
        "         save_gdrive=False,\n",
        "         learning_rate=1e-4,\n",
        "         batch_size=256)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfdd17f53c3f40f8a70d32533cdde614",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1248751.0), HTML(value='')), layout=Layou…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "11/14/2020 07:19:10 — INFO — aitextgen.TokenDataset — Encoding 1,248,751 sets of tokens from input (Cleaned).txt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "11/14/2020 07:19:48 — INFO — lightning — GPU available: True, used: True\n",
            "No environment variable for node rank defined. Set as 0.\n",
            "11/14/2020 07:19:48 — WARNING — lightning — No environment variable for node rank defined. Set as 0.\n",
            "CUDA_VISIBLE_DEVICES: [0]\n",
            "11/14/2020 07:19:48 — INFO — lightning — CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ef4ba6a6c6541edb802774673a88a76",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=25000.0), HTML(value='')), layout=Layout(…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m1,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m1,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">I'll take some cetes.\n",
            "\n",
            "==========\n",
            "\u001b[1m1,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m2,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m2,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">I've heard of your mom's a bit.\n",
            "\n",
            "==========\n",
            "\u001b[1m2,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m3,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m3,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">No way.\n",
            "\n",
            "==========\n",
            "\u001b[1m3,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m4,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m4,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">It's always been a while...\n",
            "\n",
            "==========\n",
            "\u001b[1m4,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m5,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m5,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">What the heck are you so strong?\n",
            "\n",
            "==========\n",
            "\u001b[1m5,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m6,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m6,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">We can't get through!\n",
            "\n",
            "==========\n",
            "\u001b[1m6,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m7,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m7,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">I'm going to get the taxi!\n",
            "\n",
            "==========\n",
            "\u001b[1m7,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m8,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m8,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">I'm sure you know it's about how  to get your hands on this island.\n",
            "\n",
            "==========\n",
            "\u001b[1m8,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m9,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m9,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">Well, yeah. I'm not sure.\n",
            "\n",
            "==========\n",
            "\u001b[1m9,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m10,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m10,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">You're the one who's got it!\n",
            "\n",
            "==========\n",
            "\u001b[1m10,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m11,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m11,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">Pardon?\n",
            "\n",
            "==========\n",
            "\u001b[1m11,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m12,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m12,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">I'm not sure you're not.\n",
            "\n",
            "==========\n",
            "\u001b[1m12,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m13,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m13,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">You could just be a pleader like us!\n",
            "\n",
            "==========\n",
            "\u001b[1m13,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m14,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m14,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">I was just thinking that I could do it.\n",
            "\n",
            "==========\n",
            "\u001b[1m14,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m15,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m15,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">It's the same time that I saw you looking for a long time.\n",
            "\n",
            "==========\n",
            "\u001b[1m15,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m16,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m16,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">That's right, you have to take the next one.\n",
            "\n",
            "==========\n",
            "\u001b[1m16,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m17,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m17,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">I did it! I didn't get it!\n",
            "\n",
            "==========\n",
            "\u001b[1m17,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m18,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m18,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">You're not the one to blame me.\n",
            "\n",
            "==========\n",
            "\u001b[1m18,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m19,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m19,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">All right!\n",
            "\n",
            "==========\n",
            "\u001b[1m19,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m20,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m20,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">It's not a joke, but you're not a man.\n",
            "\n",
            "==========\n",
            "\u001b[1m20,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m21,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m21,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">The world is a world of magic, so it's a shame it is in the light,\n",
            "\n",
            "==========\n",
            "\u001b[1m21,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m22,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m22,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">I'm sure you don't have to go out with me.\n",
            "\n",
            "==========\n",
            "\u001b[1m22,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m23,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m23,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">That's what it was.\n",
            "\n",
            "==========\n",
            "\u001b[1m23,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m24,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m24,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">Day after day comes, I'll be waiting for you\n",
            "\n",
            "==========\n",
            "\u001b[1m24,500 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m25,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m25,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ">You can use this.\n",
            "\n",
            "==========\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11/14/2020 09:06:31 — INFO — aitextgen — Saving trained model pytorch_model.bin to /trained_model\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOJZs076DSgs"
      },
      "source": [
        "# Generate Samples\n",
        "Finally, the fun part! Have the model generate 25 unique samples. As you can see, the results are quite believable. Please use this code responsibly, never to intentionally deceive or do evil with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsb7-rtti8Sc",
        "outputId": "ebfaeb47-9da6-46fd-ebc1-70b5a782a4a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ai.generate(n=25,\n",
        "            batch_size=16384,\n",
        "            prompt=\">\",\n",
        "            temperature=1,\n",
        "            top_p=0.99999)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m>\u001b[0mSynchronizing, huh?\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mThat's all it was for. - Let's eat.\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mHot... Ahiru-san, I just got it!\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mthe \"Disciple\"?! (That guy is from the Public Safety Bureau!\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mTest.\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mThis isn't right...\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mI just happened to be at a  place where I run a little.\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mHuh?\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mThe moment you fall,  it really razor the same piece as it gets.\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mI would rather feel bad to  tell with each other.\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mOh, I know!\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mI think I could say that I saw it.\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mYou have no right to say that.\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mAoba Johsai Shopping Dawn\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mAssuming shell.\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mYeah...\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mI see.\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mWhy? Why did Usui-kun do that?\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mWhat?\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mHuh?\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mAre you hungry?\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mLet me see those two back then!\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mOkay!\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mI don't know if I was being sucked in by a human face,\n",
            "\n",
            "==========\n",
            "\u001b[1m>\u001b[0mAnd then, at least it has to be Takahashi in grade school.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IFj1jGzXpQV",
        "outputId": "cceb8f64-4403-4e61-ba27-0be20e6c03c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!export \"model_archive=anime_subtitlegen_$(date +%e_%b_%Y_%H_%M_%S)\" ; mkdir $model_archive ; mv aitextgen-* $model_archive ; mv trained_model $model_archive ; tar -cvf $model_archive.tar $model_archive ; mv $model_archive.tar \"drive/My Drive/\" ; echo \"Model successfully backup up to Google Drive. Feel free to factory reset the runtime.\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "anime_subtitlegen_14_Nov_2020_09_06_32/\n",
            "anime_subtitlegen_14_Nov_2020_09_06_32/aitextgen-merges.txt\n",
            "anime_subtitlegen_14_Nov_2020_09_06_32/trained_model/\n",
            "anime_subtitlegen_14_Nov_2020_09_06_32/trained_model/pytorch_model.bin\n",
            "anime_subtitlegen_14_Nov_2020_09_06_32/trained_model/config.json\n",
            "anime_subtitlegen_14_Nov_2020_09_06_32/aitextgen-vocab.json\n",
            "Model successfully backup up to Google Drive. Feel free to factory reset the runtime.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjGg1f-mBcrd"
      },
      "source": [
        "# Credits\n",
        "\n",
        "This project was made possible by the cumulative efforts of the following parties:\n",
        "\n",
        "Brian Lechthaler *author of this notebook*\n",
        "* https://github.com/brianlechthaler\n",
        "* https://twitter.com/brianlechthaler\n",
        "\n",
        "Max Woolf *author of [aitextgen](https://github.com/minimaxir/aitextgen), the training code this notebook is based on.*\n",
        "* https://minimaxir.com/\n",
        "* https://github.com/minimaxir\n",
        "\n",
        "Jess Fan [author](https://www.kaggle.com/jef1056) of [anime-subtitles](https://www.kaggle.com/jef1056/anime-subtitles) dataset\n",
        "* https://github.com/JEF1056\n",
        "* https://www.linkedin.com/in/jess-fan-677177196/\n",
        "\n",
        "OpenAI *creators of [GPT-2](https://en.wikipedia.org/wiki/OpenAI#GPT-2) model*\n",
        "* https://openai.com \n",
        "* https://openai.com/blog/tags/gpt-2/\n"
      ]
    }
  ]
}